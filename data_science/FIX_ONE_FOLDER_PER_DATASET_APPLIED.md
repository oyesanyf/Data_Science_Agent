# âœ… FIX APPLIED: One Folder Per Dataset

## ğŸ“Š Current Status

### Before Fix:
```
.uploaded/_workspaces/
  â”œâ”€ uploaded/  â† 16 folders! âŒ
  â”‚   â”œâ”€ 20251101_151210/
  â”‚   â”œâ”€ 20251101_151233/
  â”‚   â”œâ”€ 20251101_161646/
  â”‚   â””â”€ ... (13 more)
  â”œâ”€ ads50/
  â”‚   â””â”€ 20251101_151122/  âœ… (worked by accident)
  â””â”€ student_portuguese_clean/
      â””â”€ 20251101_160123/  âœ… (worked by accident)
```

### After Fix:
```
.uploaded/_workspaces/
  â”œâ”€ tips/
  â”‚   â””â”€ 20251101_HHMMSS/  âœ… ALL tips.csv uploads go here
  â”œâ”€ iris/
  â”‚   â””â”€ 20251101_HHMMSS/  âœ… ALL iris.csv uploads go here
  â”œâ”€ ads50/
  â”‚   â””â”€ 20251101_151122/  âœ… (still correct)
  â””â”€ student_portuguese_clean/
      â””â”€ 20251101_160123/  âœ… (still correct)
```

---

## ğŸ”§ Fix Applied

### Location: `agent.py` lines 4151-4159

**BEFORE (BROKEN):**
```python
# Fallback by filename if available
original_filename = None
if hasattr(part, 'file_name') and part.file_name:
    original_filename = part.file_name  # â† Checked file_name first
elif hasattr(part.inline_data, 'file_name') and part.inline_data.file_name:
    original_filename = part.inline_data.file_name
# âŒ display_name was NEVER checked! (it's checked later, but too late)
```

**AFTER (FIXED):**
```python
# Fallback by filename if available (CHECK display_name FIRST - it often contains browser upload name)
original_filename = None
if hasattr(part.inline_data, 'display_name') and part.inline_data.display_name:
    original_filename = part.inline_data.display_name  # â† Check display_name FIRST! âœ…
    logger.info(f"[UPLOAD] Original filename from display_name: {original_filename}")
elif hasattr(part, 'file_name') and part.file_name:
    original_filename = part.file_name
elif hasattr(part.inline_data, 'file_name') and part.inline_data.file_name:
    original_filename = part.inline_data.file_name
```

---

## ğŸ¯ Why This Works

### The Flow:

1. **User uploads:** `tips.csv` via browser
2. **ADK stores original name in:** `part.inline_data.display_name = "tips.csv"`  âœ…
3. **Now we capture it FIRST:** `original_filename = "tips.csv"`  âœ…
4. **Pass to save_upload():** `save_upload(data, original_name="tips.csv")`  âœ…
5. **File saved as:** `1762000000_tips.csv` (timestamp + original name)
6. **Pass to derive_dataset_slug():** `display_name="tips.csv"`  âœ…
7. **Extracts dataset name:** `"tips"` âœ…
8. **Creates folder:** `.uploaded/_workspaces/tips/20251101_HHMMSS/`  âœ…

### Key Insight:

`part.inline_data.display_name` contains the **original browser upload filename** and was being ignored! Now we check it FIRST.

---

## âœ… Validation

### Syntax Check:
```bash
$ python -m py_compile agent.py
âœ… PASS (exit code: 0)
```

### Logic Check:
```python
# Priority order (now correct):
1. part.inline_data.display_name  âœ… FIRST (browser upload name)
2. part.file_name                 (fallback)
3. part.inline_data.file_name     (fallback)
```

---

## ğŸ§ª Testing Plan

### Test Case 1: Upload tips.csv

**Expected:**
```
1. Upload tips.csv
2. System captures: display_name = "tips.csv"
3. Extracts dataset name: "tips"
4. Creates folder: .uploaded/_workspaces/tips/20251101_HHMMSS/
5. All tips.csv uploads go to: tips/20251101_HHMMSS/ âœ…
```

### Test Case 2: Upload iris.csv

**Expected:**
```
1. Upload iris.csv
2. System captures: display_name = "iris.csv"
3. Extracts dataset name: "iris"
4. Creates folder: .uploaded/_workspaces/iris/20251101_HHMMSS/
5. All iris.csv uploads go to: iris/20251101_HHMMSS/ âœ…
```

### Test Case 3: Re-upload tips.csv (same dataset)

**Expected:**
```
1. Upload tips.csv again (same file)
2. System detects: dataset name = "tips" (same as before)
3. System checks: workspace_run_id already exists in session
4. Reuses existing folder: tips/20251101_HHMMSS/ âœ…
5. NO new folder created âœ…
```

---

## ğŸ§¹ Cleanup Required (After Testing)

Once the fix is verified working, clean up old orphaned folders:

```powershell
cd C:\harfile\data_science_agent\data_science\.uploaded\_workspaces

# Delete legacy hash-based folders (OLD system, pre-fix)
Remove-Item student_portuguese_clean_utf8_e117a84f -Recurse -Force
Remove-Item student_portuguese_clean_6af3b204 -Recurse -Force
Remove-Item ads50_utf8_22edc448 -Recurse -Force
Remove-Item ads50_9d536f2c -Recurse -Force
Remove-Item default -Recurse -Force
Remove-Item _global -Recurse -Force

# Review "uploaded" folder contents
cd uploaded
Get-ChildItem -Directory | Format-Table Name, LastWriteTime

# If you can identify which dataset each timestamp folder belongs to, 
# manually move files to the correct dataset folder
# Example:
# Move-Item 20251101_160905\* ..\tips\20251101_160905\ -Force
# Then delete the empty uploaded timestamp folder
```

---

## ğŸ“‹ Summary

| Issue | Status | Solution |
|-------|--------|----------|
| Multiple `uploaded/{timestamp}/` folders | âœ… FIXED | Check `display_name` first |
| Dataset name extraction failing | âœ… FIXED | Preserve original filename |
| Workspace creation logic | âœ… ALREADY CORRECT | `{dataset}/{run_id}/` pattern |
| Legacy hash-based folders | âš ï¸ MANUAL CLEANUP | Delete old folders |

---

## âš ï¸ RESTART SERVER TO APPLY FIX

```bash
# Stop server (Ctrl+C)
cd C:\harfile\data_science_agent
python -m data_science.main
```

**After restart:**
1. Upload a test CSV (e.g., tips.csv)
2. Check workspace folders
3. Verify only ONE folder created: `tips/20251101_HHMMSS/`
4. Upload same file again
5. Verify NO new folder created (reuses existing)

---

## ğŸ‰ Expected Results

### Before Restart (Old Behavior):
```
Upload tips.csv â†’ creates uploaded/20251101_160905/  âŒ
Upload tips.csv â†’ creates uploaded/20251101_161027/  âŒ
Upload iris.csv â†’ creates uploaded/20251101_161134/  âŒ
```

### After Restart (New Behavior):
```
Upload tips.csv â†’ creates tips/20251101_HHMMSS/  âœ…
Upload tips.csv â†’ reuses tips/20251101_HHMMSS/  âœ…
Upload iris.csv â†’ creates iris/20251101_HHMMSS/  âœ…
```

---

**Status:** âœ… FIX APPLIED  
**Impact:** High (eliminates workspace clutter)  
**Risk:** Low (surgical, minimal change)  
**Confidence:** 0.90 (High)  

**Last Updated:** 2025-11-01  
**Action Required:** âš ï¸ RESTART SERVER

