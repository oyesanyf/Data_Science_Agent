"""
Workflow tool guards - ensures models, evaluation, prediction, and reports save artifacts.

All workflow tools now follow the universal guard pattern (like plot_tool_guard):
- Models → saved to models/ folder
- Evaluation metrics → saved to reports/ or metrics/ folder
- Predictions → saved to reports/ folder
- Reports → saved to reports/ folder

This module provides guards for:
- Model training tools (train_baseline_model, train_tool, etc.)
- Evaluation tools (evaluate_tool)
- Prediction tools (predict_tool, classify_tool)
- Report tools (export_executive_report - already has guard but uses universal pattern)
"""
from __future__ import annotations

import logging
from pathlib import Path
from typing import Any, Dict, Optional
from .universal_tool_guard import universal_tool_guard
from .universal_async_sync_helper import async_sync_safe

logger = logging.getLogger(__name__)


def _discover_models(state: dict) -> list:
    """Discover model files from workspace."""
    ws = (state or {}).get("workspace_paths", {}) or {}
    models_dir = ws.get("models")
    if not models_dir or not Path(models_dir).exists():
        return []
    # Find all model files (joblib, pkl, h5, etc.)
    model_extensions = ['.joblib', '.pkl', '.pickle', '.h5', '.pt', '.pth', '.onnx']
    found = []
    for ext in model_extensions:
        found.extend(Path(models_dir).glob(f"*{ext}"))
    # Sort by modification time (newest first)
    return [str(p) for p in sorted(found, key=lambda x: x.stat().st_mtime, reverse=True)[:20]]


def _discover_reports(state: dict, pattern: str = "*.md") -> list:
    """Discover report files from workspace."""
    ws = (state or {}).get("workspace_paths", {}) or {}
    reports_dir = ws.get("reports")
    if not reports_dir or not Path(reports_dir).exists():
        return []
    return [str(p) for p in sorted(
        Path(reports_dir).glob(pattern),
        key=lambda x: x.stat().st_mtime,
        reverse=True
    )[:20]]


def _discover_metrics(state: dict) -> list:
    """Discover metrics files from workspace."""
    ws = (state or {}).get("workspace_paths", {}) or {}
    metrics_dir = ws.get("metrics")
    if not metrics_dir or not Path(metrics_dir).exists():
        return []
    return [str(p) for p in sorted(
        Path(metrics_dir).glob("*.json"),
        key=lambda x: x.stat().st_mtime,
        reverse=True
    )[:20]]


@async_sync_safe
async def train_baseline_model_tool_guard(tool_context=None, **kwargs):
    """Guard for train_baseline_model_tool - saves model to models/ folder."""
    from .adk_safe_wrappers import train_baseline_model_tool
    
    # Call inner tool
    result = train_baseline_model_tool(tool_context=tool_context, **kwargs)
    
    # Use universal guard pattern
    return await universal_tool_guard(
        tool_name="train_baseline_model",
        inner_tool=lambda **k: result,  # Already called
        artifact_type="model",
        artifact_dir="models",
        artifact_extension=".joblib",
        tool_context=tool_context,
        kwargs={},
        discover_artifacts_fn=_discover_models,
        result_artifact_keys=["artifacts", "model_path", "model_paths", "models"],
    )


@async_sync_safe
async def train_tool_guard(tool_context=None, **kwargs):
    """Guard for train_tool - saves model to models/ folder."""
    from .adk_safe_wrappers import train_tool
    
    # Call inner tool
    result = train_tool(tool_context=tool_context, **kwargs)
    
    # Use universal guard pattern
    return await universal_tool_guard(
        tool_name="train",
        inner_tool=lambda **k: result,
        artifact_type="model",
        artifact_dir="models",
        artifact_extension=".joblib",
        tool_context=tool_context,
        kwargs={},
        discover_artifacts_fn=_discover_models,
        result_artifact_keys=["artifacts", "model_path", "model_paths", "models"],
    )


@async_sync_safe
async def evaluate_tool_guard(tool_context=None, **kwargs):
    """Guard for evaluate_tool - saves metrics to reports/ or metrics/ folder."""
    from .adk_safe_wrappers import evaluate_tool
    
    # Call inner tool
    result = evaluate_tool(tool_context=tool_context, **kwargs)
    
    # Save evaluation results as markdown artifact
    def _save_evaluation_artifact(tc, display_text: str):
        """Save evaluation results as markdown artifact."""
        state = getattr(tc, "state", {}) if tc else {}
        workspace_root = state.get("workspace_root")
        if workspace_root and display_text:
            artifact_path = Path(workspace_root) / "reports" / "evaluation_results.md"
            artifact_path.parent.mkdir(parents=True, exist_ok=True)
            markdown_content = f"""# Model Evaluation Results

{display_text}

---
*Generated by evaluate() tool*
"""
            artifact_path.write_text(markdown_content, encoding="utf-8")
            return str(artifact_path)
        return None
    
    # Save markdown if we have display content
    if tool_context and result.get("__display__"):
        artifact_path = _save_evaluation_artifact(tool_context, result.get("__display__", ""))
        if artifact_path:
            result.setdefault("artifacts", []).append(artifact_path)
    
    # Use universal guard pattern
    return await universal_tool_guard(
        tool_name="evaluate",
        inner_tool=lambda **k: result,
        artifact_type="report",
        artifact_dir="reports",
        artifact_extension=".md",
        tool_context=tool_context,
        kwargs={},
        discover_artifacts_fn=lambda state: _discover_reports(state, "evaluation*.md") + _discover_metrics(state),
        result_artifact_keys=["artifacts", "metrics_path", "report_path", "files"],
    )


@async_sync_safe
async def predict_tool_guard(tool_context=None, **kwargs):
    """Guard for predict_tool - saves predictions to reports/ folder."""
    from .adk_safe_wrappers import predict_tool
    
    # Call inner tool
    result = predict_tool(tool_context=tool_context, **kwargs)
    
    # Save predictions as markdown artifact
    def _save_prediction_artifact(tc, display_text: str):
        """Save prediction results as markdown artifact."""
        state = getattr(tc, "state", {}) if tc else {}
        workspace_root = state.get("workspace_root")
        if workspace_root and display_text:
            artifact_path = Path(workspace_root) / "reports" / "predictions.md"
            artifact_path.parent.mkdir(parents=True, exist_ok=True)
            markdown_content = f"""# Prediction Results

{display_text}

---
*Generated by predict() tool*
"""
            artifact_path.write_text(markdown_content, encoding="utf-8")
            return str(artifact_path)
        return None
    
    # Save markdown if we have display content
    if tool_context and result.get("__display__"):
        artifact_path = _save_prediction_artifact(tool_context, result.get("__display__", ""))
        if artifact_path:
            result.setdefault("artifacts", []).append(artifact_path)
    
    # Use universal guard pattern
    return await universal_tool_guard(
        tool_name="predict",
        inner_tool=lambda **k: result,
        artifact_type="report",
        artifact_dir="reports",
        artifact_extension=".md",
        tool_context=tool_context,
        kwargs={},
        discover_artifacts_fn=lambda state: _discover_reports(state, "prediction*.md"),
        result_artifact_keys=["artifacts", "predictions_path", "output_path", "files"],
    )


@async_sync_safe
async def classify_tool_guard(tool_context=None, **kwargs):
    """Guard for classify_tool - saves classification results to reports/ folder."""
    from .adk_safe_wrappers import classify_tool
    
    # Call inner tool
    result = classify_tool(tool_context=tool_context, **kwargs)
    
    # Save classification results as markdown artifact
    def _save_classification_artifact(tc, display_text: str):
        """Save classification results as markdown artifact."""
        state = getattr(tc, "state", {}) if tc else {}
        workspace_root = state.get("workspace_root")
        if workspace_root and display_text:
            artifact_path = Path(workspace_root) / "reports" / "classification_results.md"
            artifact_path.parent.mkdir(parents=True, exist_ok=True)
            markdown_content = f"""# Classification Results

{display_text}

---
*Generated by classify() tool*
"""
            artifact_path.write_text(markdown_content, encoding="utf-8")
            return str(artifact_path)
        return None
    
    # Save markdown if we have display content
    if tool_context and result.get("__display__"):
        artifact_path = _save_classification_artifact(tool_context, result.get("__display__", ""))
        if artifact_path:
            result.setdefault("artifacts", []).append(artifact_path)
    
    # Use universal guard pattern
    return await universal_tool_guard(
        tool_name="classify",
        inner_tool=lambda **k: result,
        artifact_type="report",
        artifact_dir="reports",
        artifact_extension=".md",
        tool_context=tool_context,
        kwargs={},
        discover_artifacts_fn=lambda state: _discover_reports(state, "classification*.md"),
        result_artifact_keys=["artifacts", "output_path", "files"],
    )


# Note: export_executive_report_tool_guard already exists in executive_report_guard.py
# It should be updated to use universal_tool_guard pattern, but that's a separate task

