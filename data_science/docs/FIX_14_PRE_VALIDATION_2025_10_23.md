# Fix #14: Pre-Validation for head/describe/shape Tools

## ğŸ¯ **User's Critical Insight**

> "if head describe of size can not run against the correct dataset the code will fail"

**ABSOLUTELY RIGHT!** Without proper validation, the tools would fail silently or return empty results when `csv_path` was missing.

---

## ğŸ› **The Problem**

**Before this fix:**
1. LLM calls `head()` or `describe()` or `shape()` without `csv_path`
2. Tools attempt auto-binding from state
3. **IF auto-binding fails, tools proceed with empty `csv_path`**
4. Inner functions fail or return empty results
5. User sees "dataset appears empty" even though dataset is valid!

---

## âœ… **The Solution: Pre-Validation**

Added **validation BEFORE tool execution** to prevent failures:

### **Files Modified:**

#### **1. data_science/head_describe_guard.py**

**For `head_tool_guard` (Lines 26-57):**
```python
# ğŸ›¡ï¸ PRE-VALIDATION: Check if csv_path is available (from kwargs or state)
csv_path = kwargs.get('csv_path', '')
if not csv_path and tool_context and hasattr(tool_context, 'state'):
    csv_path = (tool_context.state.get("default_csv_path") or 
               tool_context.state.get("dataset_csv_path") or "")
    if csv_path:
        print(f"[HEAD GUARD] âœ… Auto-recovered csv_path from state: {csv_path}", flush=True)

if not csv_path:
    # Return helpful error IMMEDIATELY - don't proceed with empty path
    return {
        "status": "error",
        "message": (
            "âŒ **Cannot run head() - No dataset specified!**\n\n"
            "**Quick Fix:**\n"
            "1. Upload a CSV file first\n"
            "2. Run `list_data_files()` to see available files\n"
            "3. Run `analyze_dataset(csv_path='your_file.csv')` to set default\n"
            "4. Or pass `csv_path` explicitly\n"
        ),
        "error": "missing_csv_path"
    }

# Only proceed if validation passed
print(f"[HEAD GUARD] âœ… Validation passed - csv_path: {csv_path}", flush=True)
result = _head_inner(tool_context=tool_context, **kwargs)
```

**For `describe_tool_guard` (Lines 158-189):**
```python
# Same validation logic as head_tool_guard
# Ensures describe() never runs without a valid dataset
```

#### **2. data_science/adk_safe_wrappers.py**

**For `shape_tool` (Lines 768-790):**
```python
# ğŸ›¡ï¸ PRE-VALIDATION: Ensure csv_path is available before proceeding
if not csv_path:
    logger.error("[shape_tool] Validation failed: No csv_path available")
    return {
        "status": "error",
        "message": (
            "âŒ **Cannot get shape - No dataset specified!**\n\n"
            "**Quick Fix:**\n"
            "1. Upload a CSV file first\n"
            "2. Run `analyze_dataset(csv_path='your_file.csv')` to set default\n"
            "3. Or pass `csv_path` explicitly: `shape(csv_path='your_file.csv')`\n"
        ),
        "error": "missing_csv_path",
        "rows": 0,
        "columns": 0
    }

logger.info(f"[shape_tool] Validation passed - proceeding with csv_path: {csv_path}")
return shape(csv_path=csv_path, tool_context=tool_context)
```

---

## ğŸ“Š **Validation Flow**

```
LLM calls head/describe/shape()
        â†“
[1] Check kwargs for csv_path
        â†“
[2] If not found, try auto-bind from state
        â†“
[3] PRE-VALIDATION: Is csv_path available?
        â†“
    YES â†’ Proceed with tool execution âœ…
        â†“
    NO â†’ Return helpful error immediately âŒ
        (Don't execute inner tool!)
```

---

## ğŸ¯ **Benefits**

1. **Fail Fast**: Errors caught BEFORE tool execution
2. **Clear Messages**: Users get actionable instructions
3. **No Silent Failures**: Tools never proceed with invalid state
4. **LLM Visibility**: Error messages are properly formatted for LLM consumption
5. **State Recovery**: Auto-binding from state still works as fallback

---

## ğŸš€ **Expected Console Output (After Upload)**

### **Case 1: Valid Dataset (Success)**
```
================================================================================
[HEAD GUARD] STARTING
================================================================================
[HEAD GUARD] kwargs keys: ['tool_context']
[HEAD GUARD] csv_path: NOT PROVIDED
[HEAD GUARD] âœ… Auto-recovered csv_path from state: 1761215442_uploaded.csv
[HEAD GUARD] âœ… Validation passed - csv_path: 1761215442_uploaded.csv
[HEAD GUARD] head_tool returned: <class 'dict'>, keys=['status', 'head', 'shape']
```

### **Case 2: Missing Dataset (Validation Failure)**
```
================================================================================
[HEAD GUARD] STARTING
================================================================================
[HEAD GUARD] kwargs keys: ['tool_context']
[HEAD GUARD] csv_path: NOT PROVIDED
[HEAD GUARD] âŒ VALIDATION FAILED - No csv_path available
[HEAD GUARD] Returning error message to LLM
```

**LLM sees:**
```
âŒ **Cannot run head() - No dataset specified!**

**Quick Fix:**
1. Upload a CSV file first
2. Run `list_data_files()` to see available files
3. Run `analyze_dataset(csv_path='your_file.csv')` to set default
```

---

## ğŸ“‹ **All 14 Fixes Now Active**

1. âœ… Memory Leak Fix
2. âœ… Parquet Support
3. âœ… Plot Generation
4. âœ… MIME Types (Artifacts)
5. âœ… MIME Types (I/O)
6. âœ… Executive Reports Async
7. âœ… Debug Print Statements
8. âœ… Auto-bind describe_tool
9. âœ… Auto-bind shape_tool
10. âœ… analyze_dataset csv_path passing
11. âœ… State .keys() fixes (5 files)
12. âœ… Async save_artifact
13. âœ… Filename logging clarity
14. âœ… **Pre-Validation (head/describe/shape)** â† NEW!

---

## ğŸ” **Why This Fix Was Critical**

Without pre-validation:
- Tools would run with `csv_path=""` or `None`
- Inner functions would fail or return `{}`
- LLM would see "dataset appears empty"
- Users would be confused (they uploaded a file!)

With pre-validation:
- Tools validate BEFORE execution
- Clear error messages guide users
- Auto-recovery from state still works
- No silent failures or empty results!

---

## âœ… **Server Status**

- Cache cleared (force refresh)
- All 14 fixes loaded
- Ready for testing with CSV upload!

