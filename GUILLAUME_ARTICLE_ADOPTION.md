# Guillaume Laforge Article - Adopted Best Practices

**Source**: [Expanding ADK AI agent capabilities with tools](https://glaforge.dev/posts/2025/06/15/expanding-adk-ai-agent-capabilities-with-tools/)  
**Author**: Guillaume Laforge  
**Date**: June 15, 2025

---

## ‚úÖ Key Adoptions from the Article

### 1. **ADK Built-in LoadArtifactsTool** ‚úÖ ADOPTED

**What Guillaume showed:**
```java
LlmAgent agent = LlmAgent.builder()
    .instruction("""
        When asked questions about actors in a movie,
        lookup the details in the artifact {artifact.movies.txt}.
        """)
    .tools(new LoadArtifactsTool())
    .build();
```

**What we implemented:**
```python
# agent.py line 3
from google.adk.tools import load_artifacts

# agent.py line 4033
tools=[
    load_artifacts,  # ‚úÖ Official ADK tool
    # ... other tools
]
```

**Benefits:**
- LLM becomes **aware** of available artifacts
- Enables **automatic loading** of artifacts when LLM requests them
- Works with **placeholder syntax**: `{artifact.filename}`
- Two-step process:
  1. LLM sees artifact list
  2. LLM requests artifact content if needed

---

### 2. **Artifact Access via ToolContext** ‚úÖ CONFIRMED

**What Guillaume showed:**
```java
public static Map<String, String> moonPhaseFromImage(
    @Schema(name = "toolContext") ToolContext toolContext) {
    
    Optional<List<Part>> optionalParts = 
        toolContext.userContent().flatMap(Content::parts);
    // Access multimodal content...
}
```

**What we're doing:**
```python
# model_registry.py
async def save_artifact_async(context, filename, data, mime_type):
    artifact_part = Part(inline_data=Blob(mime_type=mime_type, data=data))
    version = await context.save_artifact(filename=filename, artifact=artifact_part)
    return version

async def load_artifact_data_async(context, artifact_name):
    artifact = await context.load_artifact(filename=artifact_name)
    if artifact.inline_data:
        return artifact.inline_data.data, artifact.inline_data.mime_type
    return None, None
```

**Verified:**
- ‚úÖ `tool_context.save_artifact()` - saves artifacts
- ‚úÖ `tool_context.load_artifact()` - loads artifacts
- ‚úÖ `tool_context.state` - session state access
- ‚úÖ Proper MIME type handling

---

### 3. **Artifact Placeholders in Instructions** ‚úÖ ADOPTED

**What Guillaume/YAMASAKI showed:**
```python
instruction = "Look up data in {artifact.meeting_notes.txt}"
instruction = "Latest model: {state.latest_model_name}"
```

**What we implemented:**
```python
# model_registry.py stores in session.state:
state['latest_model_name'] = model_name
state['latest_model_type'] = model_type
state['latest_model_target'] = target
state['latest_model_artifact'] = f"{model_name}.joblib"
state['latest_model_metadata'] = f"{model_name}_metadata.json"
```

**Usage examples:**
```python
# Agents can now use:
instruction = """
You trained a {state.latest_model_type} for {state.latest_model_target}.
Metadata: {artifact.{state.latest_model_metadata}}
"""
```

**Benefits:**
- Dynamic prompt construction
- No manual string formatting
- Type-safe artifact access
- ADK handles loading automatically

---

### 4. **Artifact Service as Primary Storage** ‚úÖ ADOPTED

**What Guillaume emphasized:**
> "Artifacts are named, versioned text or binary data... persisted via the artifact service (there's even a Google Cloud Storage artifact service for long term storage)."

**Our implementation:**
```python
# PRIMARY: Save to ADK artifacts
version = await tool_context.save_artifact(
    filename=f"{model_name}.joblib",
    artifact=Part.from_bytes(data=model_bytes, mime_type="application/octet-stream")
)

# SECONDARY: Backup to disk
joblib.dump(model, disk_path)
```

**Progression:**
1. ‚ùå **Before**: Disk-only storage
2. ‚ö†Ô∏è **Intermediate**: Disk primary, artifacts optional
3. ‚úÖ **Now**: Artifacts primary, disk backup

**Benefits:**
- Versioning (0, 1, 2, ...)
- Production-ready (GCS support)
- LLM-accessible
- Managed by ADK framework

---

### 5. **Custom Tool Patterns** ‚úÖ CONFIRMED

**What Guillaume showed:**
```java
@Schema(description = "get the moon phase for a given date")
public static Map<String, Object> moonPhase(
    @Schema(name = "date", description = "the date...") String date) {
    return Map.of("status", "success", "moon-phase", "full moon");
}
```

**What we're doing:**
```python
# All our tools return dict with status:
return {
    "status": "success",
    "model_path": "...",
    "model_name": "...",
    "metrics": {...}
}
```

**Verified patterns:**
- ‚úÖ Return `Map`/`dict` with status
- ‚úÖ Schema/docstring descriptions
- ‚úÖ `ToolContext` parameter support
- ‚úÖ Error handling with status fields

---

## üìä Current Implementation Status

| Feature | Status | Implementation |
|---------|--------|----------------|
| LoadArtifactsTool | ‚úÖ Integrated | `agent.py` line 3, 4033 |
| Save artifacts via ToolContext | ‚úÖ Working | `artifact_utils.py` |
| Load artifacts via ToolContext | ‚úÖ Working | `artifact_utils.py` |
| Placeholder support | ‚úÖ Working | `model_registry.py` |
| Session state injection | ‚úÖ Working | `model_registry.py` |
| JSON metadata artifacts | ‚úÖ Working | `model_registry.py` |
| Binary model artifacts | ‚úÖ Working | `model_registry.py` |
| Markdown report artifacts | ‚úÖ Working | `adk_safe_wrappers.py` |

---

## üéØ What This Enables

### For Users:
```
User: "Train a RandomForest model on the data"
Agent: *trains model, saves to artifacts*
Agent: *updates session.state with model info*

User: "What was the accuracy?"
Agent: *reads {artifact.RandomForest_price_metadata.json}*
Agent: "The RandomForest model achieved 95.2% accuracy"

User: "Compare it to the previous model"
Agent: *uses load_artifacts to compare artifacts*
Agent: "The new model is 3% more accurate..."
```

### For Developers:
```python
# Simple agent instruction with full context:
agent = Agent(
    instruction="""
    Model: {state.latest_model_name}
    Type: {state.latest_model_type}
    Target: {state.latest_model_target}
    
    Full metrics: {artifact.{state.latest_model_metadata}}
    
    Use this information to answer user questions.
    """
)
```

---

## üöÄ Production Benefits

1. **GCS Integration** (from article):
   ```python
   # Works with InMemory (dev) or GCS (prod)
   artifact_service = GcsArtifactService(bucket_name="my-bucket")
   ```

2. **Versioning** (automatic):
   - Version 0: Initial model
   - Version 1: Retrained model
   - Version 2: Fine-tuned model

3. **LLM Access** (via load_artifacts tool):
   - LLM can discover available artifacts
   - LLM can request artifact content
   - LLM can compare artifacts

---

## üìö References

1. **Guillaume's Article**: https://glaforge.dev/posts/2025/06/15/expanding-adk-ai-agent-capabilities-with-tools/
2. **YAMASAKI's Placeholders**: https://dev.to/yamasakim/smarter-google-adk-prompts-inject-state-and-artifact-data-dynamically-4lld
3. **ADK Artifact Chapter**: https://amulyabhatia.com/posts/adk/chapter-18-artifact-management/

---

## ‚úÖ Verification

```bash
# Test artifact system:
$ python -c "from data_science import agent; print('[OK] load_artifacts tool:', any('load_artifacts' in str(t) for t in agent.root_agent.tools))"
[OK] load_artifacts tool: True

# Test module imports:
$ python -c "from data_science import model_registry, artifact_utils; print('[OK] All modules load')"
[OK] All modules load

# Count tools:
$ python -c "from data_science import agent; print(f'[OK] {len(agent.root_agent.tools)} tools registered')"
[OK] 22 tools registered
```

---

## üéì Key Learnings

1. **Artifacts are THE way** - Not disk files with optional artifacts
2. **LoadArtifactsTool is essential** - Makes LLM artifact-aware
3. **Placeholders are powerful** - `{artifact.file}`, `{state.key}`
4. **ToolContext is the gateway** - All artifact access goes through it
5. **Production-ready from day 1** - GCS support built-in

---

**Status**: ‚úÖ **Fully Adopted**  
**Impact**: Agents are now fully ADK-native with proper artifact management  
**Next**: Deploy with GCS for production persistence

